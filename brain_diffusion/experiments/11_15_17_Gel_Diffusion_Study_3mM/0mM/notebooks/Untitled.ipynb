{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import scipy.stats as stat\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {}\n",
    "parameters[\"channels\"] = [\"RED\"]\n",
    "parameters[\"surface functionalities\"] = [\"PEG\"]\n",
    "parameters[\"slices\"] = [\"S1\", \"S2\", \"S3\", \"S4\"]\n",
    "parameters[\"videos\"] = [1, 2, 3, 4, 5]\n",
    "\n",
    "channels = parameters[\"channels\"]\n",
    "surface_functionalities = parameters[\"surface functionalities\"]\n",
    "slices = parameters[\"slices\"]\n",
    "videos = parameters[\"videos\"]\n",
    "\n",
    "geoM2xy = {}\n",
    "gSEM = {}\n",
    "SM1x = {}\n",
    "SM1y = {}\n",
    "SM2xy = {}\n",
    "npar = {}\n",
    "\n",
    "DIR = \"E:/Tracking_Videos/Gel_Studies/11_15_17_Gel_Study_37C_72pH/3mM/Output/\"\n",
    "cond = '37C_pH72'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for channel in channels:\n",
    "    for surface_functionality in surface_functionalities:\n",
    "        slice_counter = 0\n",
    "        for slic in slices:\n",
    "            for video in videos:\n",
    "                sample_name = \"{}_{}_{}_{}_{}\".format(channel, surface_functionality, cond, slic, video)                \n",
    "                #SM2xy[sample_name] = np.genfromtxt('SM2xy_{}.csv'.format(sample_name, delimiter=\",\"))\n",
    "                \n",
    "                #npar[sample_name] = SM2xy[sample_name].shape\n",
    "                geoM2xy[sample_name] = np.genfromtxt(DIR+'geoM2xy_{}.csv'.format(sample_name, delimiter=\",\"))\n",
    "                gSEM[sample_name] = np.genfromtxt(DIR+'gSEM_{}.csv'.format(sample_name, delimiter=\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "geo_slices = {}\n",
    "gSEM_slices = {}\n",
    "w_slices = {}\n",
    "wo_slices = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\koolk\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:16: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "#Calculate the precision weights over videos\n",
    "#Alternately, can weight by the number of particles in each video\n",
    "nvids = 5\n",
    "nslices = 4\n",
    "frames = 651\n",
    "\n",
    "for channel in channels:\n",
    "    for surface_functionality in surface_functionalities:\n",
    "        slice_counter = 0\n",
    "        for slic in slices:\n",
    "            video_counter = 0\n",
    "            w_holder = np.zeros((nvids, frames))\n",
    "            sample_name = \"{}_{}_{}_{}\".format(channel, surface_functionality, cond, slic)\n",
    "            for key in geoM2xy:\n",
    "                if sample_name in key:\n",
    "                    w_holder[video_counter, :] = 1/(gSEM[key]*gSEM[key])\n",
    "                    video_counter = video_counter + 1\n",
    "            wo_slices[sample_name] = np.sum(w_holder, axis=0)\n",
    "            slice_counter = slice_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Calculate the weights SEMs and means over videos\n",
    "#Remember to use alternate if not wanting to use precision weights at this level.\n",
    "for channel in channels:\n",
    "    for surface_functionality in surface_functionalities:\n",
    "        slice_counter = 0\n",
    "        for slic in slices:\n",
    "            geo_holder = np.zeros((nvids, frames))\n",
    "            gSEM_holder = np.zeros((nvids, frames))\n",
    "            w_holder = np.zeros((nvids, frames))\n",
    "            video_counter = 0\n",
    "            sample_name = \"{}_{}_{}_{}\".format(channel, surface_functionality, cond, slic)\n",
    "            for key in geoM2xy:\n",
    "                if sample_name in key:\n",
    "                    w_holder[video_counter, :] = (1/(gSEM[key]*gSEM[key]))/wo_slices[sample_name]\n",
    "                    geo_holder[video_counter, :] = w_holder[video_counter, :] * geoM2xy[key]\n",
    "                    gSEM_holder[video_counter, :] = (1/(gSEM[key]*gSEM[key]))\n",
    "                    video_counter = video_counter + 1\n",
    "            geo_slices[sample_name] = np.sum(geo_holder, axis=0)\n",
    "            gSEM_slices[sample_name] = np.sqrt((1/np.sum(gSEM_holder, axis=0)))\n",
    "            slice_counter = slice_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "geo = {}\n",
    "gS = {}\n",
    "w_slices = {}\n",
    "wo_slices = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Calculate the precision weights over slices\n",
    "for channel in channels:\n",
    "    counter = 0\n",
    "    for surface_functionality in surface_functionalities:\n",
    "        w_holder = np.zeros((nslices, frames))\n",
    "        slice_counter = 0\n",
    "        sample_name = \"{}_{}_{}\".format(channel, surface_functionality, cond)\n",
    "        for key in geo_slices:\n",
    "            if sample_name in key:\n",
    "                w_holder[slice_counter, :] = 1/(gSEM_slices[key]*gSEM_slices[key])\n",
    "                slice_counter = slice_counter + 1\n",
    "        wo_slices[sample_name] = np.sum(w_holder, axis=0)\n",
    "        counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Calculate the weights SEMs and means over slices\n",
    "for channel in channels:\n",
    "    counter = 0\n",
    "    for surface_functionality in surface_functionalities:\n",
    "        geo_holder = np.zeros((nslices, frames))\n",
    "        gSEM_holder = np.zeros((nslices, frames))\n",
    "        w_holder = np.zeros((nslices, frames))\n",
    "        slice_counter = 0\n",
    "        sample_name = \"{}_{}_{}\".format(channel, surface_functionality, cond)\n",
    "        for key in geo_slices:\n",
    "            if sample_name in key:\n",
    "                w_holder[slice_counter, :] = (1/(gSEM_slices[key]*gSEM_slices[key]))/wo_slices[sample_name]\n",
    "                geo_holder[slice_counter, :] = w_holder[slice_counter, :] * geo_slices[key]\n",
    "                gSEM_holder[slice_counter, :] = (1/(gSEM_slices[key]*gSEM_slices[key]))\n",
    "                slice_counter = slice_counter + 1\n",
    "        geo[sample_name] = np.sum(geo_holder, axis=0)\n",
    "        gS[sample_name] = np.sqrt((1/np.sum(gSEM_holder, axis=0)))\n",
    "        counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for key in geo:\n",
    "    np.savetxt(DIR+'geoM2xy_{}.csv'.format(key), geo[key], delimiter=',')\n",
    "    np.savetxt(DIR+'gSEM_{}.csv'.format(key), gS[key], delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SM2xy = np.genfromtxt('SM2xy_RED_nPEG_37C_72pH_S1.csv', delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SM2xy[10, 100:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x10 = ma.log(SM2xy[10, :]) #take the log of the MSDS at a single timpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x= np.mean(x10) #take the mean of the logs (geometric mean)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y= stat.sem(x10) #find the standard error around the mean of the logs (exponentiate to get confidence intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#an example, pretending to find weighted averages over 11 videos\n",
    "SEM = np.zeros([1, 10])\n",
    "theta = np.zeros([1, 10])\n",
    "w = np.zeros([1, 10])\n",
    "\n",
    "#create some fake averages and SEMs for demonstration purposes\n",
    "for i in range(0, 11):\n",
    "    theta[0, i - 1] = x + random.random()\n",
    "    SEM[0, i - 1] = y + random.random()\n",
    "\n",
    "wi = np.sum(1./(SEM*SEM))\n",
    "\n",
    "for i in range(0, 11):\n",
    "    w[0, i -1] = (1/(SEM[0, i-1]*SEM[0, i-1]))/wi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "otheta = np.sum(w*theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oSEM = np.sqrt(1/(np.sum(SEM*SEM)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oSEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#where real calculations begin, not limited to one row.\n",
    "\n",
    "#performing averages over an entire dataset of MSDs at all timepoints\n",
    "geoMSD = np.mean(ma.log(SM2xy), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "geoMSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gSEM = stat.sem(ma.log(SM2xy), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frames = 651\n",
    "\n",
    "SEM = np.zeros([frames, 10])\n",
    "theta = np.zeros([frames, 10])\n",
    "w = np.zeros([frames, 10])\n",
    "\n",
    "for i in range(0, 11):\n",
    "    theta[:, i-1] = geoMSD + np.random.rand(frames)*0.01\n",
    "    SEM[:, i-1] = gSEM + np.random.rand(frames)*0.0001\n",
    "\n",
    "wi = np.sum((1./(SEM*SEM)), axis=1)\n",
    "\n",
    "for i in range(0, 11):\n",
    "    w[:, i-1] = (1/(SEM[:, i-1]*SEM[:, i-1]))/wi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "otheta = np.sum(w*theta, axis=1)\n",
    "oSEM = np.sqrt(1/(np.sum(1/(SEM*SEM), axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oetheta = np.exp(otheta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loetheta = np.exp(otheta - 1.96*oSEM)\n",
    "hoetheta = np.exp(otheta + 1.96*oSEM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loetheta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
