{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primary purpose of this code is to (1) calculate MSD data from input xy(z) data, (2) perform averages over user-defined groups e.g. average over pups in a litter or replicate samples, and (3) visualize these as MSD plots and diffusion coefficient bar graphs.\n",
    "\n",
    "Data inputs are xy(z) trajectory data in csv files, as output from the MOSAIC Particle Tracker in ImageJ (I. F. Sbalzarini and P. Koumoutsakos.  Feature Point Tracking and Trajectory Analysis for Video Imaging in Cell Biology, Journal of Structural Biology 151(2):182-195, 2005).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unpack Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#REQUIRES USER INPUT\n",
    "#User must modify module_path to location where MSD_utils.py is located.\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('C:\\\\Users\\\\koolk\\\\Desktop\\\\brain-diffusion\\\\Chad_functions_and_unittests'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import scipy.optimize as opt\n",
    "import scipy.stats as stat\n",
    "from operator import itemgetter\n",
    "import random\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import numpy.linalg as la\n",
    "\n",
    "pi = np.pi\n",
    "sin = np.sin\n",
    "cos = np.cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from MSD_utils import get_data_pups, build_time_array, return_average, avg_all, graph_single_variable\n",
    "from MSD_utils import SD_all, return_SD, range_and_ticks, choose_y_axis_params, data_prep_for_plotting_pups\n",
    "from MSD_utils import fill_in_and_split, plot_traj_length_histogram, plot_traj, filter_out_short_traj\n",
    "from MSD_utils import plot_trajectory_overlay, quality_control\n",
    "\n",
    "from MSD_utils import diffusion_coefficient_point_derivative, diffusion_coefficient_linear_regression\n",
    "from MSD_utils import calculate_diffusion_coefficients, diffusion_bar_chart, summary_barcharts\n",
    "from MSD_utils import calculate_MMSDs, plot_general_histogram, plot_MSD_histogram, plot_all_MSD_histograms\n",
    "from MSD_utils import fillin2, MSD_iteration, vectorized_MMSD_calcs\n",
    "from MSD_utils import get_data_gels, data_prep_for_plotting_gels, plot_all_MSD_histograms_gels, quality_control_gels\n",
    "from MSD_utils import calculate_diffusion_coefficients_gels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Driver "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user define all parameters for desire analysis here (input organization, analysis parameters, output organization, etc).\n",
    "\n",
    "The utility of this code is its ability to iterate over all samples in an entire experiment covering multiple variables (repetitions, pups, particle types, media types, temperatures, etc).  This requires a very organized nomenclature for files for which the user is responsible before performing an analysis.  This naming structure is transferred here to iterate through files and perform analyses.  The user should record experiment parameters in the \"parameters\" dictionary, defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Defined experiment parameters\n",
    "#Note: defined in two different ways for practicality.  The dictionary is used as an input to functions (Debating usefulness of\n",
    "    #this duplicate method.  Originally, \"parameters\" had a fixed structure, so if I edited that structure, I would have to \n",
    "    #update all the functions downstream of it.  This is not useful.  I have to either generalize the functions, or not use\n",
    "    #functions at all.)\n",
    "\n",
    "parameters = {}\n",
    "parameters[\"channels\"] = [\"RED\", \"YG\"]\n",
    "#parameters[\"genotypes\"] = [\"WT\"]\n",
    "#parameters[\"pups\"] = [\"P1\", \"P2\", \"P3\"]\n",
    "parameters[\"surface functionalities\"] = [\"PEG\", \"nPEG\"]\n",
    "parameters[\"slices\"] = [\"1\", \"2\", \"3\"]\n",
    "# parameters[\"regions\"] = [\"cortex\"]\n",
    "parameters[\"replicates\"] = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "parameters[\"slice suffixes\"] = ['a', 'b', 'c']\n",
    "\n",
    "channels = parameters[\"channels\"]\n",
    "#genotypes = parameters[\"genotypes\"]\n",
    "#pups = parameters[\"pups\"]\n",
    "surface_functionalities = parameters[\"surface functionalities\"]\n",
    "slices = parameters[\"slices\"]\n",
    "#regions = parameters[\"regions\"]\n",
    "replicates = parameters[\"replicates\"]\n",
    "suffixes = parameters[\"slice suffixes\"]\n",
    "\n",
    "#Files structure and hierarchy\n",
    "#Uses a variable name that will be filled in using the parameters defined above.\n",
    "\n",
    "folder = \"./{functionality}/{slic}/\"\n",
    "path = \"./{functionality}/{slic}/geoM2xy_{sample_name}.csv\"\n",
    "frames = 480\n",
    "SD_frames = [1, 10, 19, 28]\n",
    "conversion = (0.16, 9.91, 1)#(0.3, 3.95, 1)\n",
    "to_frame = 60\n",
    "dimension = \"2D\"\n",
    "time_to_calculate = 1\n",
    "\n",
    "base = \"0-4p_agarose\"\n",
    "base_name = \"RED\"\n",
    "test_bins = np.linspace(0, 75, 76)\n",
    "\n",
    "# name = 'RED_KO_PEG_P1_S1_cortex'\n",
    "cut = 4\n",
    "totvids = 10\n",
    "frame_m = 480  # atm I can't go lower than the actual value.\n",
    "conversion = (0.16, 9.95, 1)\n",
    "\n",
    "\n",
    "\n",
    "y_range, ticks_y, dec_y, x_range, ticks_x, dec_x = 8, 2, 1, 3, 1, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "geoM1x = {}\n",
    "geoM1y = {}\n",
    "geoM2xy = {}\n",
    "SM1x = {}\n",
    "SM1y = {}\n",
    "SM2xy = {}\n",
    "\n",
    "for channel in channels:\n",
    "    for surface_functionality in surface_functionalities:\n",
    "        slice_counter = 0\n",
    "        for slic in slices:\n",
    "            suffix = suffixes[slice_counter]\n",
    "            sample_name = \"{}_{}_0-4p_agarose_{}\".format(channel, surface_functionality, slic)\n",
    "            DIR = folder.format(functionality = surface_functionality, slic = slic)\n",
    "            total1, xs, ys, x, y = MSD_iteration(DIR, sample_name, cut, totvids, conversion, frame_m)\n",
    "\n",
    "            geoM1x[sample_name], geoM1y[sample_name], geoM2xy[sample_name], SM1x[sample_name], SM1y[sample_name],\\\n",
    "                SM2xy[sample_name] = vectorized_MMSD_calcs(frames, total1, xs, ys, x, y, frame_m)\n",
    "            np.savetxt(DIR+'geoM2xy_{}.csv'.format(sample_name), geoM2xy[sample_name], delimiter=',')\n",
    "            np.savetxt(DIR+'SM2xy_{}.csv'.format(sample_name)), SM2xy[sample_name], delimiter=',')\n",
    "\n",
    "            slice_counter = slice_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data, avg_over_slices, time, time_SD, average_over_slices, all_SD_over_slices = \\\n",
    "    data_prep_for_plotting_gels(path, frames, SD_frames, conversion, to_frame, parameters);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_all_MSD_histograms_gels(parameters, folder, SM2xy, time, test_bins, 1, set_y_limit=True, y_range=5000, set_x_limit=True, x_range=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder = \"./{functionality}/{slic}/\"\n",
    "path = \"./{functionality}/{slic}/geoM2xy_{sample_name}.csv\"\n",
    "path2 = \"./{functionality}/{slic}/Traj_{sample_name}.tif.csv\"\n",
    "\n",
    "frames = 120\n",
    "SD_frames2 = [1, 2, 3, 4]\n",
    "conversion = (1.24, 1.93, 1)#(0.3, 3.95, 1)\n",
    "to_frame = 60\n",
    "dimension = \"2D\"\n",
    "time_to_calculate = 1\n",
    "\n",
    "base = \"0-4p_agarose\"\n",
    "base_name = \"RED\"\n",
    "test_bins = np.linspace(0, 75, 76)\n",
    "\n",
    "# name = 'RED_KO_PEG_P1_S1_cortex'\n",
    "cut = 4\n",
    "totvids = 10\n",
    "frame_m = 120  # atm I can't go lower than the actual value.\n",
    "\n",
    "parameters = {}\n",
    "parameters[\"channels\"] = [\"RED\"]\n",
    "parameters[\"surface functionalities\"] = [\"nPEG\"]\n",
    "parameters[\"slices\"] = [\"1\", \"2\", \"3\", \"4\"]\n",
    "parameters[\"replicates\"] = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "parameters[\"slice suffixes\"] = ['a', 'b', 'c', 'd']\n",
    "\n",
    "\n",
    "channels = parameters[\"channels\"]\n",
    "surface_functionalities = parameters[\"surface functionalities\"]\n",
    "slices = parameters[\"slices\"]\n",
    "replicates = parameters[\"replicates\"]\n",
    "suffixes = parameters[\"slice suffixes\"]\n",
    "\n",
    "frames2 = 120\n",
    "interv = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total particles after merging datasets and filtering short trajectories: 1232\n",
      "Total particles after merging datasets and filtering short trajectories: 1051\n",
      "Total particles after merging datasets and filtering short trajectories: 989\n",
      "Total particles after merging datasets and filtering short trajectories: 940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\koolk\\Miniconda3\\lib\\site-packages\\scipy\\stats\\stats.py:314: RuntimeWarning: divide by zero encountered in log\n",
      "  log_a = np.log(a)\n"
     ]
    }
   ],
   "source": [
    "geoM1x = {}\n",
    "geoM1y = {}\n",
    "geoM2xy = {}\n",
    "SM1x = {}\n",
    "SM1y = {}\n",
    "SM2xy = {}\n",
    "\n",
    "for channel in channels:\n",
    "    for surface_functionality in surface_functionalities:\n",
    "        slice_counter = 0\n",
    "        for slic in slices:\n",
    "            suffix = suffixes[slice_counter]\n",
    "            sample_name = \"{}_{}_0-4p_agarose_{}\".format(channel, surface_functionality, slic)\n",
    "            DIR = folder.format(functionality = surface_functionality, slic = slic)\n",
    "            frames, total1, xs, ys, x, y = MSD_iteration(DIR, sample_name, cut, totvids, conversion, frame_m, suffix)\n",
    "\n",
    "            geoM1x[sample_name], geoM1y[sample_name], geoM2xy[sample_name], SM1x[sample_name], SM1y[sample_name],\\\n",
    "                SM2xy[sample_name] = vectorized_MMSD_calcs(frames, total1, xs, ys, x, y, frame_m)\n",
    "            np.savetxt(DIR+'geoM2xy_{}.csv'.format(sample_name), geoM2xy[sample_name], delimiter=',')\n",
    "            np.savetxt(DIR+'SM2xy_{}.csv'.format(sample_name)), SM2xy[sample_name], delimiter=',')\n",
    "\n",
    "            slice_counter = slice_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data2, avg_over_slices2, time2, time_SD2, average_over_slices2, all_SD_over_slices2 = \\\n",
    "    data_prep_for_plotting_gels(path, frames2, SD_frames2, conversion, to_frame, parameters, base);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_all_MSD_histograms_gels(parameters, base, folder, SM2xy, time2, test_bins, 1, set_y_limit=True, y_range=5000, set_x_limit=True, x_range=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\koolk\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:123: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\koolk\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:124: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\koolk\\Miniconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:564: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  n = np.zeros(bins, ntype)\n",
      "C:\\Users\\koolk\\Miniconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:611: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  n += np.bincount(indices, weights=tmp_w, minlength=bins).astype(ntype)\n",
      "C:\\Users\\koolk\\Miniconda3\\lib\\site-packages\\matplotlib\\pyplot.py:516: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "quality_control_gels(path2, folder, frames, conversion, parameters, base, interv, cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def quality_control_gels(path2, folder, frames, conversion, parameters, base, interv, cut):\n",
    "    \"\"\"\n",
    "    This function plots a histogram of trajectory lengths (in units of frames) and two types of plots of\n",
    "    trajectories (original and overlay).\n",
    "\n",
    "    Inputs:\n",
    "    path2: string.  Name of input trajectory csv files.\n",
    "    folder: string. Name of folder to which to save results.\n",
    "    frames: integer.  Total number of frames in videos.\n",
    "    conversion: array.  Contains microns per pixel and frames per second of videos.\n",
    "    parameters:\n",
    "\n",
    "    parameters = {}\n",
    "    parameters[\"channels\"] = [\"RED\"]\n",
    "    parameters[\"surface functionalities\"] = [\"PEG\"]\n",
    "    parameters[\"slices\"] = [\"S1\", \"S2\", \"S3\"]\n",
    "    parameters[\"replicates\"] = [1, 2, 3, 4]\n",
    "\n",
    "    cut: integer.  Minimum number of frames a trajectory must have in order to be plotted.\n",
    "    \"\"\"\n",
    "\n",
    "    channels = parameters[\"channels\"]\n",
    "    surface_functionalities = parameters[\"surface functionalities\"]\n",
    "    slices = parameters[\"slices\"]\n",
    "    replicates = parameters[\"replicates\"]\n",
    "    SD_frames = [1, 7, 14, 15]\n",
    "\n",
    "    trajectory = {}\n",
    "    names_with_replicates = {}\n",
    "    data = {}\n",
    "\n",
    "    particles_unfiltered = {}\n",
    "    framed_unfiltered = {}\n",
    "    x_data_unfiltered = {}\n",
    "    y_data_unfiltered = {}\n",
    "    total_unfiltered = {}\n",
    "    particles = {}\n",
    "    framed = {}\n",
    "    x_data = {}\n",
    "    y_data = {}\n",
    "    total = {}\n",
    "    tlength = {}\n",
    "    x_microns = {}\n",
    "    y_microns = {}\n",
    "    x_particle = {}\n",
    "    y_particle = {}\n",
    "\n",
    "    x_original_frames = {}\n",
    "    y_original_frames = {}\n",
    "\n",
    "    x_adjusted_frames = {}\n",
    "    y_adjusted_frames = {}\n",
    "\n",
    "    counter2 = 0\n",
    "\n",
    "    for channel in channels:\n",
    "            for surface_functionality in surface_functionalities:\n",
    "                        for slic in slices:\n",
    "                            for replicate in replicates:\n",
    "                                # Establishing sample names and extracting data from csv files.\n",
    "                                counter2 = counter2 + 1\n",
    "                                sample_name_long = \"{}_{}_{}_{}_{}\".format(channel, surface_functionality, base, slic, replicate)\n",
    "                                names_with_replicates[counter2] = sample_name_long\n",
    "\n",
    "                                filename = path2.format(functionality = surface_functionality, slic = slic, sample_name=sample_name_long)\n",
    "                                data[sample_name_long] = np.genfromtxt(filename, delimiter=\",\")\n",
    "                                data[sample_name_long] = np.delete(data[sample_name_long], 0, 1)\n",
    "\n",
    "                                # Names of output plots\n",
    "                                fold = folder.format(functionality = surface_functionality, slic = slic)\n",
    "                                \n",
    "                                logplot = fold +'{}_logplot'.format(sample_name_long)\n",
    "                                Mplot = fold +'{}_Mplot'.format(sample_name_long)\n",
    "                                Dplot = fold +'{}_Dplot'.format(sample_name_long)\n",
    "                                Hplot = fold +'{}_Hplot'.format(sample_name_long)\n",
    "                                Hlogplot = fold +'{}_Hlogplot'.format(sample_name_long)\n",
    "                                Cplot = fold +'{}_Cplot'.format(sample_name_long)\n",
    "                                Tplot = fold +'{}_Tplot'.format(sample_name_long)\n",
    "                                T2plot = fold +'{}_T2plot'.format(sample_name_long)\n",
    "                                lenplot = fold +'{}_lenplot'.format(sample_name_long)\n",
    "\n",
    "                                # Fill in data and split into individual trajectories\n",
    "                                particles_unfiltered[counter2], framed_unfiltered[counter2], x_data_unfiltered[counter2],\\\n",
    "                                    y_data_unfiltered[counter2] = fill_in_and_split(data[names_with_replicates[counter2]])\n",
    "\n",
    "                                total_unfiltered[counter2] = int(max(particles_unfiltered[counter2]))\n",
    "\n",
    "                                # Filter out short trajectories\n",
    "                                particles[counter2], framed[counter2], x_data[counter2], y_data[counter2] =\\\n",
    "                                    filter_out_short_traj(particles_unfiltered[counter2], framed_unfiltered[counter2],\n",
    "                                                          x_data_unfiltered[counter2], y_data_unfiltered[counter2], cut)\n",
    "\n",
    "                                # Convert to microns and seconds\n",
    "                                time, time_SD = build_time_array(frames, conversion, SD_frames)\n",
    "                                framen = np.linspace(0, frames, frames+1).astype(np.int64)\n",
    "                                total[counter2] = int(max(particles[counter2]))\n",
    "                                tlength[counter2] = np.zeros(total[counter2])\n",
    "\n",
    "                                x_microns[counter2] = x_data[counter2]*conversion[0]\n",
    "                                y_microns[counter2] = y_data[counter2]*conversion[0]\n",
    "\n",
    "                                # Adjust frames (probably unneccesary, but I did it...)\n",
    "                                x_particle[counter2] = {}\n",
    "                                y_particle[counter2] = {}\n",
    "\n",
    "                                x_original_frames[counter2] = {}\n",
    "                                y_original_frames[counter2] = {}\n",
    "\n",
    "                                x_adjusted_frames[counter2] = {}\n",
    "                                y_adjusted_frames[counter2] = {}\n",
    "\n",
    "                                for num in range(1, total[counter2] + 1):\n",
    "                                    hold = np.where(particles[counter2] == num)\n",
    "                                    itindex = hold[0]\n",
    "                                    min1 = min(itindex)\n",
    "                                    max1 = max(itindex)\n",
    "                                    x_particle[counter2][num] = x_microns[counter2][min1:max1+1]\n",
    "                                    y_particle[counter2][num] = y_microns[counter2][min1:max1+1]\n",
    "\n",
    "                                    x_original_frames[counter2][num] = np.zeros(frames + 1)\n",
    "                                    y_original_frames[counter2][num] = np.zeros(frames + 1)\n",
    "                                    x_adjusted_frames[counter2][num] = np.zeros(frames + 1)\n",
    "                                    y_adjusted_frames[counter2][num] = np.zeros(frames + 1)\n",
    "\n",
    "                                    x_original_frames[counter2][num][framed[counter2][min1]:framed[counter2][max1]+1]\\\n",
    "                                        = x_microns[counter2][min1:max1+1]\n",
    "                                    y_original_frames[counter2][num][framed[counter2][min1]:framed[counter2][max1]+1]\\\n",
    "                                        = y_microns[counter2][min1:max1+1]\n",
    "\n",
    "                                    x_adjusted_frames[counter2][num][0:max1+1-min1] = x_microns[counter2][min1:max1+1]\n",
    "                                    y_adjusted_frames[counter2][num][0:max1+1-min1] = y_microns[counter2][min1:max1+1]\n",
    "\n",
    "                                    x_original_frames[counter2][num] = ma.masked_equal(x_original_frames[counter2][num], 0)\n",
    "                                    y_original_frames[counter2][num] = ma.masked_equal(y_original_frames[counter2][num], 0)\n",
    "                                    x_adjusted_frames[counter2][num] = ma.masked_equal(x_adjusted_frames[counter2][num], 0)\n",
    "                                    y_adjusted_frames[counter2][num] = ma.masked_equal(y_adjusted_frames[counter2][num], 0)\n",
    "\n",
    "                                    tlength[counter2][num - 1] = ma.count(x_adjusted_frames[counter2][num])\n",
    "\n",
    "                                plot_traj(x_original_frames[counter2], y_original_frames[counter2], total[counter2], interv, T2plot)\n",
    "                                plt.gcf().clear()\n",
    "                                plot_trajectory_overlay(x_original_frames[counter2], y_original_frames[counter2], 6, 2, 6, Tplot)\n",
    "                                plt.gcf().clear()\n",
    "                                plot_traj_length_histogram(tlength[counter2], max(tlength[counter2]), lenplot)\n",
    "                                plt.gcf().clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Datasets Together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because my PEG and nPEG datasets had different framerates, I had to analyze the datasets separately.  My code requires all datasets to have the same framerate, and thus they can't be plotted together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creates figure\n",
    "\n",
    "line_colors=['g', 'r', 'b', 'c', 'm', 'k']\n",
    "line_kind='-'\n",
    "labels = ['PEG', 'nPEG']\n",
    "label_size=95\n",
    "legend_size=40 \n",
    "tick_size=50\n",
    "line_width=10\n",
    "fig_size=(20, 18)\n",
    "filename = 'test.png'\n",
    "\n",
    "to_graph = {}\n",
    "counter = 0\n",
    "for keys in average_over_slices:\n",
    "    to_graph[counter] = keys\n",
    "    counter = counter + 1\n",
    "for keys in average_over_slices2:\n",
    "    to_graph[counter] = keys\n",
    "    counter = counter + 1\n",
    "\n",
    "fig = plt.figure(figsize=fig_size, dpi=80)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "line_type = [s + line_kind for s in line_colors]\n",
    "ax.plot(time[0:to_frame], average_over_slices[to_graph[0]][0:to_frame], line_type[0], linewidth=line_width, label=labels[0])\n",
    "ax.errorbar(time_SD, average_over_slices[to_graph[0]][SD_frames], all_SD_over_slices[to_graph[0]], fmt='', linestyle='',\n",
    "            capsize=7, capthick=2, elinewidth=2, color=line_colors[0])\n",
    "\n",
    "ax.plot(time2[0:to_frame], average_over_slices2[to_graph[1]][0:to_frame], line_type[1], linewidth=line_width, label=labels[1])\n",
    "ax.errorbar(time_SD2, average_over_slices2[to_graph[1]][SD_frames2], all_SD_over_slices2[to_graph[1]], fmt='', linestyle='',\n",
    "            capsize=7, capthick=2, elinewidth=2, color=line_colors[1])\n",
    "\n",
    "# A few adjustments to prettify the graph\n",
    "for item in ([ax.xaxis.label, ax.yaxis.label] +\n",
    "             ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    item.set_fontsize(tick_size)\n",
    "\n",
    "xmajor_ticks = np.arange(0, x_range+0.0001, ticks_x)\n",
    "ymajor_ticks = np.arange(0, y_range+0.0001, ticks_y)\n",
    "\n",
    "ax.set_xticks(xmajor_ticks)\n",
    "plt.xticks(rotation=-30)\n",
    "ax.set_yticks(ymajor_ticks)\n",
    "ax.title.set_fontsize(tick_size)\n",
    "ax.set_xlabel('Time (s)', fontsize=label_size)\n",
    "ax.set_ylabel(r'MSD ($\\mu$m$^2$)', fontsize=label_size)\n",
    "ax.tick_params(direction='out', pad=16)\n",
    "ax.legend(loc=(0.02, 0.75), prop={'size': legend_size})\n",
    "plt.gca().xaxis.set_major_formatter(mpl.ticker.FormatStrFormatter('%.{}f'.format(dec_x)))\n",
    "plt.gca().yaxis.set_major_formatter(mpl.ticker.FormatStrFormatter('%.{}f'.format(dec_y)))\n",
    "\n",
    "# plt.yscale('log')\n",
    "# plt.xscale('log')\n",
    "plt.gca().set_xlim([0, x_range+0.0001])\n",
    "plt.gca().set_ylim([0, y_range+0.0001])\n",
    "\n",
    "# Save your figure\n",
    "plt.savefig('{}'.format(filename), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_diffusion_coefficients_gels(channels, surface_functionalities, slices, path, time, time_to_calculate, to_frame, dimension):\n",
    "\n",
    "    \"\"\"\n",
    "    Loads data from csv files and outputs a dictionary following a specified\n",
    "        sample naming convection determined by the input\n",
    "\n",
    "    Parameters:\n",
    "    channels, surface functionalities, media, and concentrations, and replicates\n",
    "        can take ranges or lists.\n",
    "    path is string with substition placeholders for concentration and sample\n",
    "        name (built from channels, surface_functionalities, media,\n",
    "        concentrations, and replicates).\n",
    "\n",
    "    Example:\n",
    "    path = \"./{genotype}/{pup}/{region}/{channel}/geoM2xy_{sample_name}.csv\";\n",
    "    get_data([\"RED\", \"YG\"], [\"WT\", \"KO\", \"HET\"], [\"P1\", \"P2\", \"P3\", \"P4\"],\n",
    "    [\"PEG\", \"noPEG\"], [\"S1\", \"S2\", \"S3\", \"S4\"], [\"cortex\", \"hipp\", \"mid\"],\n",
    "    [1, 2, 3, 4, 5], path)\n",
    "    \"\"\"\n",
    "\n",
    "    data = {}\n",
    "    avg_over_slices_raw = {}\n",
    "    avg_over_pups_raw = {}\n",
    "    names_with_replicates = {}\n",
    "    counter = 0\n",
    "    counter2 = 0\n",
    "\n",
    "    diffusion_coef_point_derivative = {}\n",
    "    diffusion_coef_linear_fit = {}\n",
    "\n",
    "    for channel in channels:\n",
    "        for surface_functionality in surface_functionalities:\n",
    "            for slic in slices:\n",
    "                test_value = \"{}_{}_0-4p_agarose_{}\".format(channel, surface_functionality, slic)\n",
    "                avg_over_slices_raw[counter] = test_value\n",
    "                counter = counter + 1\n",
    "                sample_name = test_value\n",
    "                for replicate in replicates:\n",
    "                    sample_name_long = test_value + \"_{}\".format(replicate)\n",
    "                    names_with_replicates[counter2] = sample_name_long\n",
    "                    counter2 = counter2 + 1\n",
    "                filename = path.format(functionality = surface_functionality, slic = slic, sample_name=sample_name)\n",
    "                data[sample_name] = np.genfromtxt(filename, delimiter=\",\")\n",
    "\n",
    "                diffusion_coef_point_derivative[sample_name] =\\\n",
    "                    diffusion_coefficient_point_derivative(data[sample_name], time, time_to_calculate, dimension)\n",
    "                diffusion_coef_linear_fit[sample_name] =\\\n",
    "                    diffusion_coefficient_linear_regression(data[sample_name], time, to_frame, dimension)\n",
    "\n",
    "    return diffusion_coef_point_derivative, diffusion_coef_linear_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "calculate_diffusion_coefficients_gels(channels, surface_functionalities, slices, path, time, time_to_calculate, to_frame, dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
