{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-07T19:56:48.013000Z",
     "start_time": "2017-07-07T19:56:47.386000Z"
    },
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#Reformat the data and pack into an hf5d file\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "directory= r'data_gen_reduced_nn_0c/'\n",
    "runs = []\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.startswith('data2c'):\n",
    "#         run = int(filename.split('_')[2].split('.')[0])\n",
    "        run = int(filename.split('data2c')[1].split('.')[0])\n",
    "#         print run\n",
    "        runs.append(run)\n",
    "print len(runs)\n",
    "def import_files(runs):\n",
    "    import time\n",
    "    boop=0\n",
    "    volts=[]\n",
    "    inputs=[]\n",
    "    st=time.time()\n",
    "    st1=time.time()\n",
    "    lintimes = np.linspace(0,2500,num=100)\n",
    "    lintimes2 = np.linspace(0,8000,num=100)\n",
    "#     lintimes3 = np.linspace(0,7051,num=100)\n",
    "    for run in sorted(runs):\n",
    "        try:\n",
    "            if True:\n",
    "                filename = 'data2c' + str(run) + '.csv'\n",
    "                data = np.genfromtxt(directory+filename, delimiter=',')\n",
    "                raw_time=data[1:,0]\n",
    "                raw_volts=data[1:,1]\n",
    "\n",
    "#                 filename2 = 'datahalfc' + str(run) + '.csv'\n",
    "#                 data2 = np.genfromtxt(directory+filename2, delimiter=',')\n",
    "\n",
    "#                 raw_time2=data2[1:,0]\n",
    "#                 raw_volts2=data2[1:,1]\n",
    "\n",
    "#                 filename3 = 'halfc_' + str(run) + '.csv'\n",
    "#                 data3 = np.genfromtxt(directory+filename3, delimiter=',')\n",
    "\n",
    "#                 raw_time3=data3[:,0]\n",
    "#                 raw_volts3=data3[:,1]\n",
    "\n",
    "                #Impose a linear fit on each data set to ensure the same number of points per trial\n",
    "                volts.append(np.interp(lintimes,raw_time,raw_volts))\n",
    "#                 temp_volts1 = np.concatenate((np.interp(lintimes,raw_time,raw_volts),np.interp(lintimes2, raw_time2, raw_volts2)),axis=0)\n",
    "#                 temp_volts2 = np.interp(lintimes3,raw_time3,raw_volts3)\n",
    "#                 volts.append(np.concatenate((temp_volts1,temp_volts2),axis=0))\n",
    "#                 volts = temp_volts1\n",
    "#                 volts.append(temp_volts1)\n",
    "                filename2 = 'input'+str(run)+'.csv'\n",
    "                data2=np.genfromtxt(directory+filename2, delimiter=',')\n",
    "#                 print data2[1:]\n",
    "#                 inputs.append(data2[1:28])\n",
    "                inputs.append(data2)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    volts=np.array(volts)\n",
    "    inputs=np.array(inputs)\n",
    "#     print volts.shape, inputs.shape\n",
    "#     print volts.shape[0]\n",
    "    train = sorted(random.sample(range(volts.shape[0]), int(volts.shape[0]*(3.0/4.))))\n",
    "    test = [x for x in range(volts.shape[0]) if x not in train]\n",
    "    P=np.array(inputs)\n",
    "#     print P.shape\n",
    "    P_mean = np.mean(inputs)\n",
    "    P_std = np.std(inputs)\n",
    "#     P = (P-P_mean)/P_std\n",
    "\n",
    "    # # Normalize the data\n",
    "    # P = (P - P.mean())/P.std()\n",
    "#     print P.shape\n",
    "\n",
    "    X_train = volts[train,:]\n",
    "    Y_train = P[train,:]\n",
    "\n",
    "    X_test = volts[test,:]\n",
    "    Y_test = P[test,:]\n",
    "\n",
    "    return [X_train, Y_train, X_test, Y_test]\n",
    "import h5py\n",
    "from tqdm import *\n",
    "def create_database(runs,num,filename,x_dim,y_dim): # Format all the data and create a single databse file\n",
    "    with h5py.File(filename+\".hdf5\", \"w\") as f:\n",
    "#         help1=import_files(runs[range(len(runs)/num)])\n",
    "        rowsize1 = 0.75*num\n",
    "        rowsize2 = num-rowsize1\n",
    "        dset1 = f.create_dataset(\"X_train\", (rowsize1,x_dim), dtype='f', maxshape=(None,x_dim), chunks=(rowsize1,x_dim), compression=\"gzip\")\n",
    "        dset2 = f.create_dataset(\"Y_train\", (rowsize1,y_dim), dtype='f', maxshape=(None,y_dim), chunks=(rowsize1,y_dim), compression=\"gzip\")\n",
    "        dset3 = f.create_dataset(\"X_test\", (rowsize2,x_dim), dtype='f', maxshape=(None,x_dim), chunks=(rowsize2,x_dim), compression=\"gzip\")\n",
    "        dset4 = f.create_dataset(\"Y_test\", (rowsize2,y_dim), dtype='f', maxshape=(None,y_dim), chunks=(rowsize2,y_dim), compression=\"gzip\")\n",
    "        leftovers=len(runs)%num\n",
    "        if leftovers > 0:\n",
    "            numruns = len(runs)/num+1\n",
    "        else:\n",
    "            numruns = len(runs)/num\n",
    "        for i in tqdm(range(numruns)):\n",
    "#             print runs[num*i:min(len(runs), (num)+num*i)]\n",
    "            try:\n",
    "                help1 = import_files(runs[num*i:num*(i+1)])\n",
    "                rowsize1 = help1[0].shape[0]\n",
    "                rowsize2 = help1[2].shape[0]\n",
    "                rowcount1 = dset1.shape[0]\n",
    "                rowcount2 = dset3.shape[0]\n",
    "            except:\n",
    "                help1 = import_files(runs[num*i:num*i+leftovers])\n",
    "                rowsize1 = help1[0].shape[0]\n",
    "                rowsize2 = help1[2].shape[0]\n",
    "                rowcount1 = dset1.shape[0]\n",
    "                rowcount2 = dset3.shape[0]\n",
    "\n",
    "            if i==0:\n",
    "                dset1[:] = help1[0]\n",
    "                dset2[:] = help1[1]\n",
    "                dset3[:] = help1[2]\n",
    "                dset4[:] = help1[3]\n",
    "            else:\n",
    "                dset1.resize(rowcount1 + rowsize1, axis=0 )\n",
    "                dset2.resize(rowcount1 + rowsize1, axis=0 ) \n",
    "                dset3.resize(rowcount2 + rowsize2, axis=0 ) \n",
    "                dset4.resize(rowcount2 + rowsize2, axis=0 ) \n",
    "\n",
    "                dset1[rowcount1:] = help1[0]\n",
    "                dset2[rowcount1:] = help1[1]\n",
    "                dset3[rowcount2:] = help1[2]\n",
    "                dset4[rowcount2:] = help1[3]\n",
    "#     print dset1.shape, dset2.shape, dset3.shape, dset4.shape\n",
    "# dset = X_train\n",
    "# dset = np.concatenate((dset,X_train),axis=0) \n",
    "# print dset1.shape, dset2.shape, dset3.shape, dset4.shape\n",
    "\n",
    "\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-27T22:06:10.037000Z",
     "start_time": "2017-06-27T22:06:10.031000Z"
    },
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# q=import_files(runs[1:10])\n",
    "print runs[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-07T20:06:39.828000Z",
     "start_time": "2017-07-07T19:56:55.963000Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 700/700 [09:41<00:00,  1.26it/s]\n"
     ]
    }
   ],
   "source": [
    "#1000 takes 50s, 150 takes 30s, 300 takes 30s, 50 takes 28s\n",
    "# directory= r'Maple_ebdae/data_gen/'\n",
    "directory = r'data_gen_nn_exp_attempt_2/'\n",
    "\n",
    "runs = []\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.startswith('data2c'):\n",
    "#         run = int(filename.split('_')[2].split('.')[0])\n",
    "        run = int(filename.split('data2c')[1].split('.')[0])\n",
    "#         print run\n",
    "        runs.append(run)\n",
    "runs = np.sort(runs)\n",
    "print len(runs)\n",
    "filename = 'P2D_data_nn_exp_sort_attempt_2_longtime'\n",
    "# import_files(runs[1:10])\n",
    "create_database(runs,100,filename,100,46) # runs, num per round, output dimensions, input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-25T17:03:40.156000Z",
     "start_time": "2017-05-25T17:03:40.137000Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30995, 200) (30995, 50) (10332, 200) (10332, 50)\n",
      "[ 110.98213959    9.27678585    0.97082967    0.4901        0.34106874\n",
      "    4.81682062    4.63150024    4.5303421     4.51685667    4.5021739\n",
      "    4.4234724     4.34631443    4.27730513    4.23673534]\n"
     ]
    }
   ],
   "source": [
    "#verify:\n",
    "f = h5py.File(filename+\".hdf5\", \"r\")\n",
    "X_train = f['X_train']\n",
    "Y_train = f['Y_train']\n",
    "X_test = f['X_test']\n",
    "Y_test = f['Y_test']\n",
    "\n",
    "print X_train.shape, Y_train.shape, X_test.shape, Y_test.shape\n",
    "print Y_train[1,21:35]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Not a dataset (Not a dataset)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-fb431d4e6e5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (C:\\Minonda\\conda-bld\\h5py_1474482483473\\work\\h5py\\_objects.c:2705)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (C:\\Minonda\\conda-bld\\h5py_1474482483473\\work\\h5py\\_objects.c:2663)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Neal-pc\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\dataset.pyc\u001b[0m in \u001b[0;36mshape\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[1;34m\"\"\"Numpy-style shape tuple giving dataset dimensions\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetter\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mwith_phil\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py\\h5d.pyx\u001b[0m in \u001b[0;36mh5py.h5d.DatasetID.shape.__get__ (C:\\Minonda\\conda-bld\\h5py_1474482483473\\work\\h5py\\h5d.c:2629)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py\\h5d.pyx\u001b[0m in \u001b[0;36mh5py.h5d.DatasetID.shape.__get__ (C:\\Minonda\\conda-bld\\h5py_1474482483473\\work\\h5py\\h5d.c:2549)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (C:\\Minonda\\conda-bld\\h5py_1474482483473\\work\\h5py\\_objects.c:2705)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (C:\\Minonda\\conda-bld\\h5py_1474482483473\\work\\h5py\\_objects.c:2663)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py\\h5d.pyx\u001b[0m in \u001b[0;36mh5py.h5d.DatasetID.get_space (C:\\Minonda\\conda-bld\\h5py_1474482483473\\work\\h5py\\h5d.c:4279)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Not a dataset (Not a dataset)"
     ]
    }
   ],
   "source": [
    "for i in range(X_train.shape[0]):\n",
    "    plt.plot(range(X_train.shape[1]),X_train[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
